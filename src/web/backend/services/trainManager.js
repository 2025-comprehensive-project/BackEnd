const { spawn } = require("child_process");
const path = require("path");
const fs = require("fs");
const axios = require("axios");
const { logger, createTrainLogger } = require("../utils/logger");
const { stopFlaskServer } = require("./flaskManager");
const { getTrainStatus, setTrainStatus, updateTrainStatus } = require("../utils/trainStatusManager");

const baseDir = path.join(__dirname, "../../../ai/chatbot");
const modelDir = path.join(baseDir, "models");
const dataDir = path.join(baseDir, "data");
const trainerDir = path.join(baseDir, "trainer");

const trainProcesses = new Map();

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const registerProcess = (version, proc) => trainProcesses.set(version, proc);
const getProcess = (version) => trainProcesses.get(version);
const abortProcess = (version) => {
  const proc = trainProcesses.get(version);
  if (proc) {
    proc.kill("SIGINT");
    trainProcesses.delete(version);
    return true;
  }
  return false;
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const getBaseModelVersions = () => {
  const basePath = path.join(modelDir, "base");
  try {
    return fs.readdirSync(basePath).filter((file) =>
      fs.statSync(path.join(basePath, file)).isDirectory()
    );
  } catch {
    return [];
  }
};

const getLoraAdapterVersions = () => {
  const loraPath = path.join(modelDir, "lora");
  try {
    return fs.readdirSync(loraPath).filter((file) =>
      fs.statSync(path.join(loraPath, file)).isDirectory()
    );
  } catch {
    return [];
  }
};

const getLoraAdapterPath = async (npc_id) => {
  const { data: npcVersions } = await axios.get(`${process.env.FLASK_BASE_URL}/npc-version`);
  const version = npcVersions[npc_id];
  if (!version) return null;
  return path.join(modelDir, "lora", version);
};

const getLatestCheckpoint = (outDir) => {
  try {
    const entries = fs.readdirSync(outDir, { withFileTypes: true });
    const ckpts = entries
      .filter(e => e.isDirectory() && /^checkpoint-\\d+$/.test(e.name))
      .map(e => ({ name: e.name, step: parseInt(e.name.split("-")[1]) }))
      .sort((a, b) => b.step - a.step);
    return ckpts.length > 0 ? ckpts[0] : null;
  } catch {
    return null;
  }
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ íŒŒì´í”„ë¼ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const runTrainPipeline = async ({
  type = "lora",
  version,
  baseModel,
  datapath,
  target,
  source = "beomi",
  train_path,
  val_path,
  epochs,
  lr,
  bsz,
  gradAcc,
  maxLen,
  merge = false,
  resume = false,
  load_in_4bit = false
}) => {
  if (type === "base") {
    try {
      logger.info("ðŸ›‘ BASE í•™ìŠµ ì‹œìž‘ ì „ Flask ì„œë²„ ì¢…ë£Œ ìš”ì²­");
      await stopFlaskServer();
    } catch (e) {
      logger.warn(`âš ï¸ Flask ì¢…ë£Œ ì‹¤íŒ¨: ${e.message}`);
    }
  }

  const trainLogger = createTrainLogger(version, type);
  const outDir = path.join(modelDir, type, version);
  const lastCheckpoint = getLatestCheckpoint(outDir);
  const shouldResume = resume && !!lastCheckpoint;

  if (shouldResume) {
    logger.info(`ðŸ” ì²´í¬í¬ì¸íŠ¸ ê°ì§€ë¨: ${lastCheckpoint.name}`);
    trainLogger.info(`ðŸ” ì²´í¬í¬ì¸íŠ¸ ê°ì§€ë¨: ${lastCheckpoint.name}`);
  } else {
    logger.info("ðŸ†• ìƒˆ í•™ìŠµ ì„¸ì…˜ ì‹œìž‘ (ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ)");
    trainLogger.info("ðŸ†• ìƒˆ í•™ìŠµ ì„¸ì…˜ ì‹œìž‘ (ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ)");
  }

  const basePath = path.join(modelDir, "base", baseModel);
  logger.info(`ðŸ“ ë² ì´ìŠ¤ ëª¨ë¸ ê²½ë¡œ: ${basePath}`);

  if (!datapath && target) {
    datapath = path.join(dataDir, "lora", target, `${target}_train.jsonl`);
    logger.info(`ðŸ§© target='${target}' ê¸°ë°˜ datapath ìžë™ ì„¤ì •: ${datapath}`);
  }

  const getTrainScriptAndArgs = async () => {
    if (type === "lora" || type === "rola") {
      const isCustom = !!datapath;
      const args = [
        "-u",
        path.join(trainerDir, type === "rola" ? "train_rola.py" : "train_lora.py"),
        "--base", basePath,
        "--out", outDir,
        "--data", datapath,
        "--epochs", epochs,
        "--bsz", bsz,
        "--lr", lr,
        "--max_len", maxLen,
        "--grad_acc", gradAcc,
        ...(shouldResume ? ["--resume"] : [])
      ];

      if (type === "rola") {
        const npc_id = version.split("-")[0];
        const loraPath = await getLoraAdapterPath(npc_id);
        if (loraPath) {
          args.push("--lora", loraPath);
          logger.info(`ðŸ” [ROLA] LoRA ì–´ëŒ‘í„° ìžë™ ì ìš©: ${loraPath}`);
        } else {
          logger.warn(`âš ï¸ [ROLA] '${npc_id}'ì— ëŒ€í•œ LoRA ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ`);
        }
      }

      return { args };
    }

    const isCustom = source === "custom";
    return {
      args: [
        "-u",
        path.join(trainerDir, "train_full_sft.py"),
        "--base", baseModel,
        "--out", outDir,
        "--source", source,
        ...(isCustom ? ["--train", train_path, "--val", val_path] : []),
        "--epochs", epochs,
        "--bsz", bsz,
        "--lr", lr,
        "--max_len", maxLen,
        "--grad_acc", gradAcc,
        ...(shouldResume ? ["--resume"] : []),
        ...(load_in_4bit ? ["--load_in_4bit"] : [])
      ]
    };
  };

  const { args } = await getTrainScriptAndArgs();

  logger.info(`ðŸš€ [${type.toUpperCase()} í•™ìŠµ ì‹œìž‘] ë²„ì „: ${version}, ì—í­: ${epochs}, lr: ${lr}, base: ${baseModel}`);
  trainLogger.info(`ðŸ”„ ${type.toUpperCase()} í•™ìŠµ ì¤‘â€¦`);

  await setTrainStatus(version, {
    status: "running",
    currentEpoch: 0,
    totalEpochs: epochs,
    percent: 0,
    lastLog: "",
    loss: null,
    startedAt: new Date().toISOString(),
    eta: null
  });

  return new Promise((resolve, reject) => {
    const train = spawn("python", args);
    registerProcess(version, train);

    let lastError = "";

    train.stdout.on("data", async (data) => {
      const lines = data.toString().split("\n");
      for (const rawLine of lines) {
        const line = rawLine.trim();
        if (!line) continue;
        trainLogger.info(`[${type.toUpperCase()}-out] ${line}`);

        const dictMatch = line.match(/['"]loss['"]:\s*([0-9.]+).*['"]epoch['"]:\s*([0-9.]+)/);
        const match = line.match(/epoch\s*(\d+)\s*\/\s*(\d+).*?loss[:=]?\s*([\d.]+)/i);

        if (dictMatch || match) {
          const loss = parseFloat(dictMatch?.[1] || match?.[3]);
          const epoch = parseFloat(dictMatch?.[2] || match?.[1]);
          const totalEpochs = parseInt(match?.[2] || epochs);
          const percent = Math.round((epoch / totalEpochs) * 100);

          const startedAt = new Date((await getTrainStatus(version))?.startedAt || new Date());
          const now = new Date();
          const elapsedMs = now - startedAt;
          const eta = epoch > 0 ? new Date(now.getTime() + (elapsedMs / epoch) * (totalEpochs - epoch)).toISOString() : null;

          await updateTrainStatus(version, {
            currentEpoch: Math.floor(epoch),
            totalEpochs,
            percent,
            lastLog: line,
            loss,
            eta
          });
        }
      }
    });

    train.stderr.on("data", (data) => {
      const msg = data.toString().trim();
      lastError = msg;
      if (/error|exception|traceback/i.test(msg)) {
        trainLogger.error(`[${type.toUpperCase()}-err] ${msg}`);
      } else {
        trainLogger.info(`[${type.toUpperCase()}-log] ${msg}`);
      }
    });

    train.on("close", async (code) => {
      const status = code === 0 ? "completed" : "failed";
      await updateTrainStatus(version, {
        status,
        ...(status === "failed" ? { errorMessage: lastError } : {})
      });

      if (status === "failed") {
        trainLogger.error(`âŒ ${type.toUpperCase()} í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ ${code})`);
        return reject(`${type} training failed: ${lastError}`);
      }

      trainLogger.info(`âœ… ${type.toUpperCase()} í•™ìŠµ ì™„ë£Œ â†’ ${outDir}`);
      logger.info(`âœ… ${type.toUpperCase()} í•™ìŠµ ì™„ë£Œ â†’ ${outDir}`);

      if (!merge || type === "base") return resolve({ [`${type}_path`]: outDir });
    });
  });
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ì‚­ì œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const deleteModel = (type, version) => {
  const targetPath = path.join(modelDir, type, version);
  if (!fs.existsSync(targetPath)) {
    throw new Error("MODEL_NOT_FOUND");
  }
  fs.rmSync(targetPath, { recursive: true, force: true });
  return true;
};

module.exports = {
  runTrainPipeline,
  abortProcess,
  getBaseModelVersions,
  getLoraAdapterVersions,
  deleteModel
};