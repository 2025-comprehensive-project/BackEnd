#!/usr/bin/env python3
# coding: utf-8
"""
Base ëª¨ë¸ í’€ íŠœë‹ (SFT) ìŠ¤í¬ë¦½íŠ¸
trainManager.js â†’ spawn("python", [...]) ë¡œ í˜¸ì¶œë¨
"""

import argparse, os, torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer, AutoModelForCausalLM,
    TrainingArguments, DataCollatorForLanguageModeling,
    BitsAndBytesConfig
)
from trl import SFTTrainer


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI íŒŒì„œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_args():
    p = argparse.ArgumentParser(description="Run Full-SFT training")
    p.add_argument("--base",      required=True, help="Base model path or HF ID")
    p.add_argument("--out",       required=True, help="Output directory for trained model")
    p.add_argument("--epochs",    type=int,   default=3,     help="Epochs")
    p.add_argument("--lr",        type=float, default=2e-5,  help="Learning rate")
    p.add_argument("--bsz",       type=int,   default=2,     help="Batch size per device")
    p.add_argument("--grad_acc",  type=int,   default=1,     help="Gradient accumulation steps")  # âœ… ì¶”ê°€ë¨
    p.add_argument("--max_len",   type=int,   default=1024,  help="Max sequence length")
    p.add_argument("--source", default="beomi", choices=["beomi", "custom", "jojo"], help="Data source")
    p.add_argument("--train",     default=None, help="Path to custom train.json")  
    p.add_argument("--val",       default=None, help="Path to custom val.json")
    p.add_argument("--dataset", default="beomi/KoAlpaca-RealQA", help="HF dataset name when source=beomi")
    p.add_argument("--resume", action="store_true", help="Resume from last checkpoint if available")
    p.add_argument("--load_in_4bit", action="store_true", help="Enable 4bit quantization")
    return p.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    args = parse_args()
    
    os.makedirs(args.out, exist_ok=True)

    print("í˜„ì¬ ë°ì´í„° ì…‹:", args.dataset)

    # âœ… source ê°’ì— ë”°ë¼ dataset ìë™ ì„¤ì •
    if args.source == "jojo":
        args.dataset = "jojo0217/korean_safe_conversation"

    os.makedirs(args.out, exist_ok=True)

    # âœ… ë°ì´í„° ë¡œë”©
    if args.source == "custom":
        if not args.train or not args.val:
            raise ValueError("ì»¤ìŠ¤í…€ í•™ìŠµ ì‹œ --train, --val ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print(f"ğŸ“¥ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘... (train: {args.train}, val: {args.val})")
        data_files = {"train": args.train, "validation": args.val}
        ds_raw = load_dataset("json", data_files=data_files)
    else:
        print(f"ğŸ“¥ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {args.dataset}")
        ds_raw = load_dataset(args.dataset)
        ds_raw = ds_raw["train"].train_test_split(test_size=0.05, seed=42)

    # âœ… ChatML ë³€í™˜ í•¨ìˆ˜
    if args.source == "jojo":
        def to_chatml(ex):
            return {
                "text": f"<|user|>\n{ex['instruction'].strip()}</s>\n<|assistant|>\n{ex['output'].strip()}</s>"
            }
    else:  # ê¸°ë³¸ beomi ë˜ëŠ” ê¸°íƒ€
        def to_chatml(ex):
            return {
                "text": f"<|user|>\n{ex.get('question', ex.get('input', '')).strip()}</s>\n<|assistant|>\n{ex.get('answer', ex.get('output', '')).strip()}</s>"
            }

    ds_train = ds_raw["train"].map(to_chatml, remove_columns=ds_raw["train"].column_names)
    ds_eval  = ds_raw["validation" if "validation" in ds_raw else "test"].map(to_chatml, remove_columns=ds_raw["train"].column_names)

    # âœ… ëª¨ë¸ ë¡œë“œ
    print(f"ğŸš€ ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ: {args.base}")
    tok = AutoTokenizer.from_pretrained(args.base, use_fast=False)
    tok.pad_token = tok.eos_token

    # âœ… 4bit ë¡œë”© ì˜µì…˜ ì²˜ë¦¬
    if args.load_in_4bit:
        print("ğŸ”§ 4bit ì–‘ìí™” ë¡œë”© í™œì„±í™”ë¨")
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.bfloat16,  # ë˜ëŠ” torch.float16
            bnb_4bit_quant_type="nf4"
        )

        model = AutoModelForCausalLM.from_pretrained(
            args.base,
            quantization_config=bnb_config,
            device_map="auto",
            trust_remote_code=True
        )
    else:
        model = AutoModelForCausalLM.from_pretrained(
            args.base,
            torch_dtype=torch.float32,
            device_map="auto",
            trust_remote_code=True
        )

    model.gradient_checkpointing_enable()
    model.config.use_cache = False

    # âœ… íŠ¸ë ˆì´ë„ˆ ì„¤ì •
    train_args = TrainingArguments(
        output_dir=args.out,
        num_train_epochs=args.epochs,
        per_device_train_batch_size=args.bsz,
        per_device_eval_batch_size=args.bsz,
        learning_rate=args.lr,
        gradient_accumulation_steps=args.grad_acc,
        fp16=not args.load_in_4bit,
        logging_steps=20,
        save_total_limit=3,
        eval_steps=500,
        optim="paged_adamw_8bit",
        overwrite_output_dir=True
    )

    trainer = SFTTrainer(
        model=model,
        train_dataset=ds_train,
        eval_dataset=ds_eval,
        tokenizer=tok,
        dataset_text_field="text",
        #data_collator=DataCollatorForLanguageModeling(tok, mlm=False),
        data_collator=None,
        max_seq_length=args.max_len,
        packing=False,
        args=train_args
    )

    # âœ… resume ì˜µì…˜ì´ Trueì¼ ê²½ìš°, rng_state.pth ì œê±°
    if args.resume:
        from glob import glob
        import shutil

        ckpts = sorted(glob(os.path.join(args.out, "checkpoint-*")), reverse=True)
        if ckpts:
            latest_ckpt = ckpts[0]
            rng_file = os.path.join(latest_ckpt, "rng_state.pth")
            if os.path.exists(rng_file):
                print(f"ğŸ§¹ Removing RNG state file: {rng_file}")
                os.remove(rng_file)

    # âœ… í•™ìŠµ ì‹¤í–‰
    trainer.train(resume_from_checkpoint=args.resume)

    # for epoch in range(1, args.epochs + 1):
    #     trainer.train(resume_from_checkpoint=args.resume)
    #     eval_result = trainer.evaluate()
    #     loss = eval_result.get("eval_loss", None)
    #     print(f"[SFT] epoch {epoch}/{args.epochs} loss={loss:.4f}", flush=True)

    trainer.save_model(args.out)
    tok.save_pretrained(args.out)
    print(f"âœ… Base ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {args.out}")

if __name__ == "__main__":
    main()
